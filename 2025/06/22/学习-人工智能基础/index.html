<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.0.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/%E5%A4%B4%E5%83%8F1.jpg">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/%E5%A4%B4%E5%83%8F1.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/%E5%A4%B4%E5%83%8F1.jpg">
  <link rel="mask-icon" href="/images/%E5%A4%B4%E5%83%8F1.jpg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"lwlaymh.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.23.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="常用激活函数Sigmoid函数$f ( x ) &#x3D; \frac { 1  } { 1 + e ^{ - x  }  } : ( - \infty , + \infty ) \to ( 0 , 1 ) $. $f ‘ ( x ) &#x3D; f ( x ) ( 1 - f ( x ) ) $. tanh函数$f ( x ) &#x3D; \frac { e ^x - e ^{ - x  }  } { e ^x +">
<meta property="og:type" content="article">
<meta property="og:title" content="人工智能基础">
<meta property="og:url" content="http://lwlaymh.github.io/2025/06/22/%E5%AD%A6%E4%B9%A0-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/index.html">
<meta property="og:site_name" content="LWLAymh的备忘录">
<meta property="og:description" content="常用激活函数Sigmoid函数$f ( x ) &#x3D; \frac { 1  } { 1 + e ^{ - x  }  } : ( - \infty , + \infty ) \to ( 0 , 1 ) $. $f ‘ ( x ) &#x3D; f ( x ) ( 1 - f ( x ) ) $. tanh函数$f ( x ) &#x3D; \frac { e ^x - e ^{ - x  }  } { e ^x +">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-06-22T08:57:48.121Z">
<meta property="article:modified_time" content="2025-06-22T08:57:48.122Z">
<meta property="article:author" content="LWLAymh">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://lwlaymh.github.io/2025/06/22/%E5%AD%A6%E4%B9%A0-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://lwlaymh.github.io/2025/06/22/%E5%AD%A6%E4%B9%A0-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/","path":"2025/06/22/学习-人工智能基础/","title":"人工智能基础"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>人工智能基础 | LWLAymh的备忘录</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/motion.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script><script src="/js/bookmark.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>






  <script src="/js/third-party/addtoany.js" defer></script>

  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>


<link rel="dns-prefetch" href="my-repository-jade-beta-79.vercel.app">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">LWLAymh的备忘录</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">混乱节拍拼凑出血肉喧嚷</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">1.</span> <span class="nav-text">常用激活函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">1.1.</span> <span class="nav-text">Sigmoid函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">1.2.</span> <span class="nav-text">tanh函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">1.3.</span> <span class="nav-text">ReLU函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">1.4.</span> <span class="nav-text">Leaky ReLU函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">1.5.</span> <span class="nav-text">Softmax函数</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">2.</span> <span class="nav-text">损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">2.1.</span> <span class="nav-text">Least Square</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">2.2.</span> <span class="nav-text">Cross Entropy</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">3.</span> <span class="nav-text">神经网络实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">3.1.</span> <span class="nav-text">梯度下降法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">3.2.</span> <span class="nav-text">误差反向传播</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link"><span class="nav-number">4.</span> <span class="nav-text">卷积神经网络(CNN)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">4.1.</span> <span class="nav-text">感受野计算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">4.2.</span> <span class="nav-text">池化(Pooling)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link"><span class="nav-number">4.3.</span> <span class="nav-text">常见卷积架构</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link"><span class="nav-number">4.3.1.</span> <span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-5"><a class="nav-link"><span class="nav-number">4.3.2.</span> <span class="nav-text">VGG</span></a></li><li class="nav-item nav-level-5"><a class="nav-link"><span class="nav-number">4.3.3.</span> <span class="nav-text">ResNet</span></a></li><li class="nav-item nav-level-5"><a class="nav-link"><span class="nav-number">4.3.4.</span> <span class="nav-text">SqueezeNet</span></a></li><li class="nav-item nav-level-5"><a class="nav-link"><span class="nav-number">4.3.5.</span> <span class="nav-text">MobileNet</span></a></li><li class="nav-item nav-level-5"><a class="nav-link"><span class="nav-number">4.3.6.</span> <span class="nav-text">ShuffleNet</span></a></li><li class="nav-item nav-level-5"><a class="nav-link"><span class="nav-number">4.3.7.</span> <span class="nav-text">反卷积</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="LWLAymh"
      src="/images/%E5%A4%B4%E5%83%8F1.jpg">
  <p class="site-author-name" itemprop="name">LWLAymh</p>
  <div class="site-description" itemprop="description">不过是白日梦里一瞬息</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">58</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/LWLAymh" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;LWLAymh" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:lwlaymh@outlook.com" title="E-Mail → mailto:lwlaymh@outlook.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="/LWLAymh" title="WeChat → LWLAymh" rel="noopener me"><i class="fab fa-skype fa-fw"></i>WeChat</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://minyuchengmin.github.io/" title="https:&#x2F;&#x2F;minyuchengmin.github.io" rel="noopener" target="_blank">ycm的blog</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="http://shanlunjiajian.github.io/" title="http:&#x2F;&#x2F;shanlunjiajian.github.io" rel="noopener" target="_blank">qyc的blog</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://www.cnblogs.com/do-while-true" title="https:&#x2F;&#x2F;www.cnblogs.com&#x2F;do-while-true" rel="noopener" target="_blank">dwt的blog</a>
            </li>
        </ul>
      </div>
    </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://lwlaymh.github.io/2025/06/22/%E5%AD%A6%E4%B9%A0-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/%E5%A4%B4%E5%83%8F1.jpg">
      <meta itemprop="name" content="LWLAymh">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LWLAymh的备忘录">
      <meta itemprop="description" content="不过是白日梦里一瞬息">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="人工智能基础 | LWLAymh的备忘录">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          人工智能基础
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-06-22 16:57:48" itemprop="dateCreated datePublished" datetime="2025-06-22T16:57:48+08:00">2025-06-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E5%AD%A6%E8%AF%BE%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">大学课程</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">Waline：</span>
  
    <a title="waline" href="/2025/06/22/%E5%AD%A6%E4%B9%A0-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/2025/06/22/%E5%AD%A6%E4%B9%A0-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><span id="more"></span>
<h3><span id="常用激活函数">常用激活函数</span></h3><h4><span id="sigmoid函数">Sigmoid函数</span></h4><p>$f ( x ) = \frac { 1  } { 1 + e ^{ - x  }  } : ( - \infty , + \infty ) \to ( 0 , 1 ) $.</p>
<p>$f ‘ ( x ) = f ( x ) ( 1 - f ( x ) ) $.</p>
<h4><span id="tanh函数">tanh函数</span></h4><p>$f ( x ) = \frac { e ^x - e ^{ - x  }  } { e ^x + e ^{ - x  }  } : ( - \infty , + \infty ) \to ( - 1 , 1 ) $.</p>
<p>$f ‘ ( x ) = 1 - f ^2 ( x ) $.</p>
<h4><span id="relu函数">ReLU函数</span></h4><p>$f ( x ) = \max ( 0 , x ) : ( - \infty , + \infty ) \to ( 0 , + \infty ) $.</p>
<h4><span id="leaky-relu函数">Leaky ReLU函数</span></h4><p>$f ( x ) = \max ( \alpha x , x ) , 0 &lt; \alpha &lt; 1 : ( - \infty , + \infty ) \to ( - \infty , + \infty ) $.</p>
<h4><span id="softmax函数">Softmax函数</span></h4><p>$f ( x _i ) = \frac { e ^{ x _i  }  } { \sum _j e ^{ x _j  }  } $.</p>
<h3><span id="损失函数">损失函数</span></h3><h4><span id="least-square">Least Square</span></h4><p>即$\arg \min \sum _{ i = 1  } ^n ( f ( x _i ) - y _i ) ^2 = \arg \min ( A \beta - Y \mid A \beta - Y ) $.用最小二乘法取$\hat \beta = ( A ^T A ) ^{ - 1  } A ^T Y $.</p>
<h4><span id="cross-entropy">Cross Entropy</span></h4><p>用错误的分布$q $来表示真实分布$p $的样本,则平均编码长度应该是:</p>
<script type="math/tex; mode=display">
H ( p , q ) = \sum _i p ( i ) \log ( \frac { 1  } { q ( i )  } ) = - \sum _i p ( i ) \log { q ( i )  }</script><p>此为交叉熵.</p>
<p>特别地,当最终样本只有两个的时候,例如Logistical Regression问题,可以写成:</p>
<script type="math/tex; mode=display">
\begin{aligned}
H & = - ( y \log a + ( 1 - y ) \log ( 1 - a ) ) \\
\frac { \partial H  } { \partial a  } & = - ( \frac { y  } { a  } - \frac { 1 - y  } { 1 - a  } ) 
\end{aligned}</script><p>那如果有多个呢?考虑直接对归一化条件作偏导,先有:</p>
<script type="math/tex; mode=display">
\begin{aligned}
H ( p , q ) & = - \sum _i p _i ( \log { q _i  } - \log ( \sum _j q _j ) ) \\
\frac { \partial H ( p , q )  } { \partial q _k  } & = - \frac { p _k  } { q _k  } + \frac { \sum p _k  } { \sum _j q _j  } \\
& = - \frac { p _k  } { q _k  } + 1 
\end{aligned}</script><p>再乘以softmax那里的$q _k $,得到$- p _k + q _k = - y _k + f ( x _k ) $.</p>
<h3><span id="神经网络实现">神经网络实现</span></h3><p>通过若干隐藏层,假设最后的输出层为第$L $层,则:</p>
<ol>
<li><p>对于第$l $层,取$\vec { z  } _l = ( W _l ) ^t \vec { a  } _{ l - 1  } + \vec { b  } _l $.这里对$W _l $作转置的目的是写代码的时候需要用行向量.</p>
</li>
<li><p>对于第$l $层,取$\vec { a  } _l = f ( \vec { z  } _l ) $,这里意味着将每一个分量对$f $操作.</p>
</li>
<li><p>对于最终答案,取误差$\mathcal { L  } = \frac { 1  } { m  } ( \vec { y  } - \vec { a  } _L \mid \vec { y  } - \vec { a  } _L ) $.</p>
</li>
</ol>
<h4><span id="梯度下降法">梯度下降法</span></h4><p>换言之就是让$w : = w - \alpha \frac { \partial \mathcal { L  }  } { \partial w  } $,其中$\alpha $是一个选定的小常数,也可以采用类似模拟退火的方式动态决定.事实上可以把各个位置分开,写作$w _j : = w _j - \alpha \frac { \partial \mathcal { L  }  } { \partial w _j  } $.</p>
<p>另外,虽然是这么写,应当见到去掉下标$k $的记号仍然合理,无非是逐分量做此操作,因此下面如无特殊说明,运算均采用逐分量运算.例如可以定义$\vec { a  } \circ \vec { b  } $为两个向量逐分量相乘后得到的新向量,为表区分用$\times $表示正常的矩阵乘法.甚至采取$( \vec { a  } - \vec { y  } ) ^2 $表示其自点积.坦白而言,笔者对此符号相当无奈,可也想不出什么更好的写法了.但总之这种写法总是强于部分参考资料上所将下标放上面的写作$a ^L $的做法.笔者所能维持的精神数院人的唯一做法也只能是在下面加上向量符号,藉此泄愤.</p>
<p>顺便一提,应当见到$\times $和$\circ $这两种运算比较随意,用线性映射来理解,你这个$W \times $任意作用在一个向量上就行.</p>
<h4><span id="误差反向传播">误差反向传播</span></h4><p>既然要用梯度下降法,就应该把每一层的偏导都求出来.然而$\mathcal { L  } $是最后一层的结果,因此应该用链式法则一路求出前面的偏导.</p>
<p>更具体地,不妨设误差函数选的是$( \vec { a  } - \vec { y  } ) ^2 $,激活函数选的是cross entropy有:</p>
<ol>
<li><p>$\frac { \partial { \mathcal { L  }  }  } { \partial \vec { a  } _{ L  }  } = ( \vec { a  } _{ L  } - \vec { y  } ) $.(如若选择不同的误差函数,这里作适当变化)</p>
</li>
<li><p>$\frac { \partial \vec { a  } _{ l  }  } { \partial \vec { z  } _{ l  }  } = f ‘ ( \vec { z  } _{ l  } ) = \vec { a  } _{ l  } \circ ( 1 - \vec { a  } _{ l  } ) $.(如若选取不同的激活函数,这里作适当变化)</p>
</li>
<li><p>$\frac { \partial \vec { z  } _{ l + 1  }  } { \partial \vec { z  } _{ l  }  } = \frac { \partial \vec { z  } _{ l + 1  }  } { \partial \vec { a  } _{ l  }  } \frac { \partial \vec { a  } _{ l  }  } { \partial \vec { z  } _{ l  }  } = ( W _{ l + 1  } ) ^t \times ( \vec { a  } _l \circ ( 1 - \vec { a  } _l ) ) $.</p>
</li>
<li><p>$\frac { \partial \vec { z  } _{ l  }  } { \partial W _{ l  }  } = ( \vec { a  } _{ l - 1  } ) $.结果理应是一个矩阵,其实就是这个列向量不断复制若干遍,或者写成$( \vec { a  } _{ l - 1  } ) ^t M ( 1 ) $,其中$M ( 1 ) $是全$1 $矩阵.</p>
</li>
<li><p>$\frac { \partial \vec { z  } _{ l  }  } { \partial \vec { b  } _{ l  }  } = 1 $.</p>
</li>
</ol>
<p>我们应当见到:</p>
<p>不妨设$\delta _l = \frac { \partial { \mathcal { L  }  }  } { \partial \vec { z  } _l  } $.见到:</p>
<ol>
<li><p>$\delta _L = \frac { \partial \mathcal { L  }  } { \partial \vec { z  } _L  } = \frac { \partial \mathcal { L  }  } { \partial \vec { a  } _L  } \frac { \partial \vec { a  } _L  } { \partial \vec { z  } _L  } = ( \vec { a  } _{ L  } - \vec { y  } ) \circ \vec { a  } _{ L  } \circ ( 1 - \vec { a  } _{ L  } ) $.前者会因为误差函数的选取而改变,后者会因为激活函数的选取而改变.</p>
</li>
<li><p>$\delta _l = \frac { \partial { \mathcal { L  }  }  } { \partial \vec { z  } _l  } = \delta _{ l + 1  } \frac { \partial \vec { z  } _{ l + 1  }  } { \partial \vec { z  } _l  } = \delta _{ l + 1  } \circ ( W _{ l + 1  } ) ^t \times ( \vec { a  } _{ l  } \circ ( 1 - \vec { a  } _{ l  } ) ) $.</p>
</li>
<li><p>$\frac { \partial \mathcal { L  }  } { \partial W _{ l  }  } = \frac { \partial \mathcal { L  }  } { \partial \vec { z  } _{ l  }  } \frac { \partial \vec { z  } _l  } { \partial W _{ l  }  } = \delta _l \times a _{ l - 1  } ^t $.</p>
</li>
<li><p>$\frac { \partial \mathcal { L  }  } { \partial \vec { b  } _l  } = \delta _l $.</p>
</li>
</ol>
<p>如此以上更新即可.</p>
<h3><span id="卷积神经网络cnn">卷积神经网络(CNN)</span></h3><p>神经网络受矩阵乘法的限制,导致对于真实的尺寸巨大的图像难以快速识别,因此产生了卷积神经网络的概念,大概有以下特征:</p>
<ol>
<li><p>空间上权值共享:不同位置使用同一个卷积核(滤波器)</p>
</li>
<li><p>稀疏链接:每一层只链接前一层的感受野.</p>
</li>
<li><p>等变表示:卷积神经网络有某种平移不变性.</p>
</li>
</ol>
<p>对于2D卷积,其公式如下:</p>
<script type="math/tex; mode=display">
S _{ r , c  } = ( X * W ) _{ r , c  } = \sum _i \sum _j X _{ r + i , c + j  } \times w _{ i , j  }</script><p>其中$W $是卷积核,$X $是输入图像,$S $是输出的结果.如果一个图像有多个通道(比如色彩层之类的),每个通道上都需要应用一个卷积核.</p>
<p>下面引入一些名词:</p>
<ol>
<li><p>input size:输入图像的尺寸.</p>
</li>
<li><p>padding:填充的像素数.</p>
</li>
<li><p>filter size:卷积核的尺寸.有时也写作两个变量:filter height和filter width.3D卷积还会有一个filter depth的变量.</p>
</li>
<li><p>stride:步长.</p>
</li>
<li><p>output size:卷积后输出的尺寸.有时也写作feature size.</p>
</li>
<li><p>input channels:输入图像的通道数.</p>
</li>
<li><p>n filters:卷积核的数量.</p>
</li>
<li><p>dilation rate:膨胀率,用于空洞卷积.膨胀率为$d $的时候,卷积核中间会插入$d - 1 $个$0 $间隔.</p>
</li>
</ol>
<h4><span id="感受野计算">感受野计算</span></h4><p>先看output size的计算,容易见到,其各个维度方面计算是独立的.只要对于单个维度算出卷积核在上面移动的次数,最后将不同维度相乘即可.</p>
<p>对于单个维度,这个维度的移动次数应该是:</p>
<script type="math/tex; mode=display">
\begin{aligned}
\text { output \_ size  } & = \lceil \frac { \text { input \_ size  } + 2 \times \text { padding  } - \text { filter \_ size  } + 1  } { \text { stride  }  } \rceil \\
& = \lfloor \frac { \text { input \_ size  } + 2 \times \text { padding  } - \text { filter \_ size  }  } { \text { stride  }  } \rfloor + 1 \\

\end{aligned}</script><p>这个公式相当容易理解,原因是$\text { stride  } = 1 $的时候,上面恰好是移动的次数,而$\text { stride  } $变化的时候,当然要拿到一个上取整.</p>
<p>至于所谓的空洞卷积,只需在上面的基础上改$\text { filter _ size  } $就好.</p>
<p>至于乘法操作,每得到一个$\text { output  } $当然都会需要$\text { filter _ size  } $次乘法操作.</p>
<p>再看感受野的计算,不妨设$S _i $为前$i $次卷积的$\text { stride  } $的乘积,设$k _{ i + 1  } $表示第$i + 1 $层的$\text { kernel _ size  } $,则:</p>
<script type="math/tex; mode=display">
RF _{ i + 1  } = RF _i + ( k _{ i + 1  } - 1 ) \times S _i</script><p>这个公式的含义大概是每次先看对应了多大的原数据上的范围,再把原本的边界$RF _i $给补上.</p>
<h4><span id="池化pooling">池化(Pooling)</span></h4><p>池化操作它没有一个可学习的参数,只是对输入数据进行固定的操作.简单来说就是降低输入的规模,以实现更好的鲁棒性以及提高效率.</p>
<p>常见的池化操作包括:</p>
<ol>
<li><p>MaxPooling:取区域内的最大值.</p>
</li>
<li><p>MeanPooling:取区域内的平均值.</p>
</li>
<li><p>PyramidPooling:多次进行尺度不同的池化.</p>
</li>
</ol>
<h4><span id="常见卷积架构">常见卷积架构</span></h4><h5><span id="alexnet">AlexNet</span></h5><p>首次引入ReLU激活函数,Dropout 技术,以及数据增强,提高了模型的训练效率和泛化能力.</p>
<p>采用了$8 $层深的网络结构,证明了深度网络的潜力.</p>
<h5><span id="vgg">VGG</span></h5><p>开始堆叠小尺寸的卷积核,获得与大卷积核相似的感受野的同时可以增加网络深度.</p>
<h5><span id="resnet">ResNet</span></h5><p>引入残差的概念,直接将输入数据累加(跳跃连接)到最后的输出中,这样网络学习的实际上是输入和输出之间的残差,从而提高了网络学习能力.</p>
<h5><span id="squeezenet">SqueezeNet</span></h5><p>SqueezeNet的基本构建单元是Fire模块.Fire模块由一个squeeze层和一个expand层组成.squeeze层使用$1 \times 1 $卷积核减少通道数,而expand层则使用$1 \times 1 $和$3 \times 3 $卷积核增加通道数.这种设计有效地减少了参数数量和计算量.</p>
<h5><span id="mobilenet">MobileNet</span></h5><ol>
<li><p>深度卷积:在这个操作中,每个输入通道独立地进行卷积,这意味着在进行卷积时,不同通道之间没有交互.这样可以减少计算量和参数数量.</p>
</li>
<li><p>逐点卷积:逐点卷积使用$1 \times 1 $的卷积核,它作用在深度卷积的输出上,将不同通道的信息整合在一起.逐点卷积可以减少参数数量,同时保持较高的性能.</p>
</li>
</ol>
<h5><span id="shufflenet">ShuffleNet</span></h5><ol>
<li><p>组卷积(Group Convolution):将通道分成几个组,并使用不同的卷积神经网络层执行标准卷积.</p>
</li>
<li><p>打乱层(Shuffle layer):通过对通道进行洗牌,将不同组的信息合并.</p>
</li>
</ol>
<h5><span id="反卷积">反卷积</span></h5><p>也就是将较小的数据特征图扩大到较大的尺寸.有的时候也把这个操作说成上采样.</p>
<ol>
<li><p>插值步骤(Interpolation Step):首先,在输入特征图的元素之间插入零,增加特征图的尺寸.</p>
</li>
<li><p>卷积步骤(Convolution Step):接下来,对扩大后的特征图应用一个标准的卷积操作.此步骤相当于在扩大的特征图上滑动卷积核,计算卷积输出.</p>
</li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"># AI</a>
          </div>

        
  <div class="social-like a2a_kit a2a_kit_size_32 a2a_default_style">
    <a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a>
      <a class="a2a_button_facebook"></a>
      <a class="a2a_button_twitter"></a>
      <a class="a2a_button_telegram"></a>
      <a class="a2a_button_wechat"></a>
      <a class="a2a_button_qzone"></a>
  </div>

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/06/22/%E5%AD%A6%E4%B9%A0-OI%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" rel="prev" title="OI中的线性代数">
                  <i class="fa fa-angle-left"></i> OI中的线性代数
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/06/22/%E5%AD%A6%E4%B9%A0-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" rel="next" title="动态规划相关">
                  动态规划相关 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="waline"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">LWLAymh</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>
<script class="next-config" data-name="waline" type="application/json">{"lang":"zh-cn","enable":true,"serverURL":"my-repository-jade-beta-79.vercel.app","cssUrl":"https://unpkg.com/@waline/client@v2/dist/waline.css","commentCount":true,"pageview":false,"placeholder":"有什么想法?","avatar":"mm","meta":["nick","mail","link"],"pageSize":10,"visitor":false,"comment_count":true,"requiredFields":[],"libUrl":"//unpkg.com/@waline/client@v2/dist/waline.js","el":"#waline","comment":true,"path":"/2025/06/22/%E5%AD%A6%E4%B9%A0-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80/"}</script>
<link rel="stylesheet" href="https://unpkg.com/@waline/client@v2/dist/waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>

  <!-- 音乐播放器 -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.0/dist/APlayer.min.css">
  <script src="https://cdn.jsdelivr.net/npm/aplayer@1.10.0/dist/APlayer.min.js"></script>
  <div id="aplayer" class="aplayer" data-id="7637648380" data-server="netease" data-type="playlist" data-fixed="true" data-listfolded="true" data-order="random" data-theme="#F58EA8"></div>
  <script src="https://unpkg.com/meting@1.2/dist/Meting.min.js"></script>
  <!-- 音乐播放器 end -->
</body>
</html>
